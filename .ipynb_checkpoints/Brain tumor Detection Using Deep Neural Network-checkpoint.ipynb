{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67321f2d",
   "metadata": {},
   "source": [
    "# Install Required  Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ee064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy\n",
    "#pip install pandas\n",
    "#pip install opencv-python\n",
    "#pip install tensorflow\n",
    "#pip install matplotlib\n",
    "#pip install sklearn\n",
    "#pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9913396",
   "metadata": {},
   "source": [
    "-> The main aim of this project is to create a convolutional neural network (CNN) which will predict wheather a brain has tumor or not the man has suffering from a disease or not </br>\n",
    "-> CNN Classification model is trained, validate, and test with different layers and other hyperparameters.</br>\n",
    "->CNN is built using TensorFlow and Keras </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20557ddb",
   "metadata": {},
   "source": [
    "# Steps to Implement Brain tumor Disease Prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a865e",
   "metadata": {},
   "source": [
    "step1: Import required libraries\n",
    "  \n",
    "step2: Import the Brain tumor Dataset\n",
    "\n",
    "step3: Visualize the images and Resize the images\n",
    "\n",
    "step4: Convert images into Numpy array and do Normalizasion\n",
    "\n",
    "step5: Visualize the class count and check for class balance or imbalance\n",
    "\n",
    "step6: Splitting the Dataset into train and test and also validate\n",
    "\n",
    "step7:  Create model architecture, compile the model and then fit it using training data\n",
    "\n",
    "step8: Plot accuracy and loss against each epoch\n",
    "\n",
    "step9: Make predictions on testing data\n",
    "\n",
    "step10: Visualize the original and predicted labels for the test images\n",
    "\n",
    "step11: Deploy the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c694d59b",
   "metadata": {},
   "source": [
    "# Step1: Import Required Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import img_to_array, array_to_img\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Activation,Flatten, Dropout, Dense, BatchNormalization, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fbdc1b",
   "metadata": {},
   "source": [
    "# Step2: Import the Brain Tumor Images Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_dataset = \"C:/Users/thiru/Tensorflow_ML_DL/Brain Tumor Major Project/brain_tumor_dataset\"\n",
    "\n",
    "non_tumor = os.listdir(os.path.join(brain_dataset, 'non_tumor_images'))\n",
    "tumor = os.listdir(os.path.join(brain_dataset, 'tumor_images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72142d7",
   "metadata": {},
   "source": [
    "# Step3: Visualize the images and Resize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "path_non_tumor_images = os.path.join(brain_dataset, 'non_tumor_images')\n",
    "\n",
    "for i in range (1,17):\n",
    "    plt.subplot(4, 4, i)\n",
    "    plt.tight_layout()\n",
    "    img = imread(path_non_tumor_images  + '/' + random.choice(sorted(os.listdir(path_non_tumor_images ))))\n",
    "    plt.imshow(img)\n",
    "    plt.title('Non Tumor Image')\n",
    "    plt.xlabel(img.shape[1], fontsize = 12)\n",
    "    plt.ylabel(img.shape[0], fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "path_tumor_images = os.path.join(brain_dataset, \"tumor_images\")\n",
    "\n",
    "for j in range(1,17):\n",
    "    plt.subplot(4,4,j)\n",
    "    plt.tight_layout()\n",
    "    img1 = imread(path_tumor_images + '/' + random.choice(os.listdir(path_tumor_images)))\n",
    "    plt.imshow(img1)\n",
    "    plt.title('Tumor Image')\n",
    "    plt.xlabel(img1.shape[1], fontsize=12)\n",
    "    plt.ylabel(img1.shape[0], fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba4ee2",
   "metadata": {},
   "source": [
    "# Step4: Convert images into Numpy array and do Normalizasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe29aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(image_directory):\n",
    "    try:\n",
    "        image = cv2.imread(image_directory)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (256, 256))\n",
    "            return img_to_array(image)\n",
    "        else: \n",
    "            return np.array([])\n",
    "    except Exception as excep:\n",
    "        print(f\"Error: (excep)\")\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7c3a3",
   "metadata": {},
   "source": [
    "Reading and converting image to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb2f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = brain_dataset\n",
    "images_list, label_list = [], []\n",
    "dataset_labels = ['non_tumor_images', 'tumor_images']\n",
    "binary_labels = [0,1]\n",
    "\n",
    "temp = -1\n",
    "for image_directory in ['non_tumor_images', 'tumor_images'] :\n",
    "    brain_image_list = listdir(f\"{directory}/{image_directory}\")\n",
    "    temp += 1\n",
    "    for files in brain_image_list:\n",
    "        image_path = f\"{directory}/{image_directory}/{files}\"\n",
    "        images_list.append(convert_image_to_array(image_path))\n",
    "        label_list.append(binary_labels[temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316e5f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea40087",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83541ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = np.array(images_list, dtype=np.float16) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea798fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = images_list.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9bcc9d",
   "metadata": {},
   "source": [
    "# Step5: Visualize the class count and check for class balance or imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76eab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_counts = pd.DataFrame(label_list).value_counts()\n",
    "labels_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f00497",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b5b6b",
   "metadata": {},
   "source": [
    "# Step6: Splitting the Dataset into train and test and also validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb3193",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(images_list, label_list, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4cc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the dataset of all images\n",
    "x_train = np.array(x_train, dtype=np.float16)/255.0\n",
    "x_test = np.array(x_test, dtype=np.float16)/255.0\n",
    "x_train = x_train.reshape(-1, 256,256,3)\n",
    "x_test = x_test.reshape(-1,256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def13de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc22e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29605c",
   "metadata": {},
   "source": [
    "# Step7: Create model architecture, compile the model and then fit it using training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17603d34",
   "metadata": {},
   "source": [
    "# Convolution Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b14d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\",input_shape=(256,256,3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bdca4",
   "metadata": {},
   "source": [
    "# Step8: Plot accuracy and loss against each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8483a",
   "metadata": {},
   "source": [
    "While compiling the model we need to set the type of loss which willbe Binary Crossentropy for ourmodel along with this we also to set the optimizer and the metrics respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.0001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb08d6",
   "metadata": {},
   "source": [
    "## training and validation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f687f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49123a7",
   "metadata": {},
   "source": [
    "Fitting the model with the data and finding at each epoch to see how our model is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fdcc71",
   "metadata": {},
   "source": [
    "## Training the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456bb13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d3fac",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"Model/brain_tumor_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988bc04b",
   "metadata": {},
   "source": [
    "# Step9: Make predictions on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Accuracy\")\n",
    "accuracy_score = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy {accuracy_score[1]*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb1dc99",
   "metadata": {},
   "source": [
    "## Make Prdection on Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537eb258",
   "metadata": {},
   "source": [
    "# Step 10: Visualize the original and predicted labels for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.plot(history.history['accuracy'],color='r')\n",
    "plt.plot(history.history['val_accuracy'], color='b')\n",
    "plt.title('Brain Tumor CNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend('train', 'val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7f072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a761e18",
   "metadata": {},
   "source": [
    "# Visualize the original and predicted labels for the testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3120cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image11 = array_to_img(x_test[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad73a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cf629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e194122",
   "metadata": {},
   "source": [
    "# Step11: Deploy the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb45c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51f02bee",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ad527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f25b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(images_list, label_list, test_size=0.2, random_state=10)\n",
    "x_val, x_test_rnn, y_val, y_test_rnn = train_test_split(x_temp, y_temp, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a43054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset of all images\n",
    "x_train = np.array(x_train, dtype=np.float16) / 255.0\n",
    "x_val = np.array(x_val, dtype=np.float16) / 255.0\n",
    "x_train = x_train.reshape(-1, 256, 256, 3)\n",
    "x_val = x_val.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce64b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image data for RNN\n",
    "x_train_rnn = x_train.reshape(-1, 256, 3 * 256)  # Reshape training data\n",
    "x_val_rnn = x_val.reshape(-1, 256, 3 * 256)      # Reshape validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RNN model\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(LSTM(128, input_shape=(256, 3 * 256), return_sequences=True))  # Increase LSTM units and add return_sequences=True\n",
    "model_rnn.add(Dropout(0.5))\n",
    "model_rnn.add(LSTM(64))  # Add another LSTM layer\n",
    "model_rnn.add(Dense(128, activation='relu'))\n",
    "model_rnn.add(Dropout(0.5))\n",
    "model_rnn.add(Dense(64, activation='relu'))\n",
    "model_rnn.add(BatchNormalization())\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_rnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the RNN model\n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85afe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the RNN model with early stopping\n",
    "epochs = 100\n",
    "batch_size = 50\n",
    "history_rnn = model_rnn.fit(x_train_rnn, y_train, batch_size=batch_size, epochs=epochs, \n",
    "                             validation_data=(x_val_rnn, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image data for RNN\n",
    "x_test_rnn = x_test_rnn.reshape(-1, 256, 3 * 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the RNN model on the test set\n",
    "print(\"Model Accuracy\")\n",
    "accuracy_score_rnn = model_rnn.evaluate(x_test_rnn, y_test_rnn)\n",
    "print(f\"Test Accuracy: {accuracy_score_rnn[1] * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ad315",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_y_pred = model_rnn.predict(x_test_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16380273",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 10))\n",
    "plt.plot(history_rnn.history['accuracy'],color='r')\n",
    "plt.plot(history_rnn.history['val_accuracy'], color='b')\n",
    "plt.title('Brain Tumor RNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend('train', 'val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8154da8",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train,x_test, y_train, y_test = train_test_split(images_list, label_list, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff951d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images into a two-dimensional array\n",
    "x_num_samples_train, height, width, channels = x_train.shape\n",
    "x_train_flattened = x_train.reshape(x_num_samples_train, height * width * channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abdd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images into a two-dimensional array\n",
    "x_num_samples_test, height, width, channels = x_test.shape\n",
    "x_test_flattened = x_test.reshape(x_num_samples_test, height * width * channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49338d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',random_state = 0)\n",
    "classifier.fit(x_train_flattened, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad94f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bbcc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49cd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test,y_pred,output_dict = True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea5f7d5",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=0)\n",
    "classifier_gb.fit(x_train_flattened, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d592601",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gb.fit(x_train_flattened, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = classifier_gb.predict(x_test_flattened)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54232957",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Accuracy Score:\", accuracy_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_gb = classification_report(y_test, y_pred_gb, output_dict=True)\n",
    "df_gb = pd.DataFrame(report_gb).transpose()\n",
    "print(\"Classification Report:\")\n",
    "print(df_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7bf499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cee5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd076b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f46b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddce24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
